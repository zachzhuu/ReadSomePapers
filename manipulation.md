# Robotic Manipulation Paper List

## Vision Language Action Models

- Feb 25 | *Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success*  
  [Github](https://github.com/moojink/openvla-oft?tab=readme-ov-file). Stanford. Comparison with [π₀](https://www.physicalintelligence.company/blog/pi0) and [RDT-1B](https://github.com/thu-ml/RoboticsDiffusionTransformer) included.

- May 25 | *3D-CAVLA: Leveraging Depth and 3D Context to Generalize Vision–Language Action Models for Unseen Tasks*  
  [page](https://3d-cavla.github.io/). Discussed depth in VLA model.

- May 25 | *GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data*  
  [arxiv](https://arxiv.org/pdf/2505.03233)

- Apr 25 | *π0.5: a Vision-Language-Action Model with Open-World Generalization*  
  [page](https://www.pi.website/blog/pi05). Physical Intelligence.

- May 25 | *OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning*  
  [page](https://one-two-vla.github.io/)

## Augmentation

- May 25 | *Augmented Reality for RObots (ARRO): Pointing Visuomotor Policies Towards Visual Robustness*  
  [page](https://augmented-reality-for-robots.github.io/). A rough paper, but discussed a true problem (**visual robustness**).

- Apr 25 | *Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation*  
  [page](https://yangsizhe.github.io/robosplat/). RSS25

## Reconstruction

- Apr 25 | *Object Reconstruction Under Occlusion by Fusing Vision and Contact-Rich Physics*  
  [page](https://vysics-vision-and-physics.github.io/). GRASP Lab. RSS25

## Representation

- May 25 | *EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation*  
  [arxiv](https://arxiv.org/pdf/2505.10105). Submitted to NeurIPS25

## Dexterous from Human/Ego

- May 25 | *DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies*  
  [page](https://dexwild.github.io/). CMU RI. RSS25. Manus gloves.

- May 25 | *EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video*  
  [arxiv](https://arxiv.org/pdf/2505.11709). Apple

- May 25 | *Web2Grasp: Learning Functional Grasps from Web Images of Hand-Object Interactions*  
  [page](https://web2grasp.github.io/)

- May 25 | *EgoZero: Robot Learning from Smart Glasses*  
  [page](https://egozero-robot.github.io/).

- May 25 | *HAND Me the Data: Fast Robot Adaptation via Hand Path Retrieval*  
  [page](https://liralab.usc.edu/handretrieval/).

- Jun 25 | *Object-centric 3D Motion Field for Robot Learning from Human Videos*  
  [page](https://zhaohengyin.github.io/3DMF/). Pieter Abbeel's lab.

## Diffusion Policy

- Mar 25 | *ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy*  
  [page](https://et-seed.github.io/). Spatial generalization. ICLR25

## Scaling Robot Learning

- May 25 | *Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware*  
  [page](https://real2render2real.com/). Berkeley

- May 25 | *X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real*  
  [page](https://portal-cornell.github.io/X-Sim/). Cornell

- May 25 | *DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories*  
  [page](https://research.nvidia.com/labs/gear/dreamgen/). Nvidia

- Apr 25 | *RoboVerse: Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning*  
  [page](https://roboverseorg.github.io/)

- Mar 25 | *What Matters in Learning from Large-Scale Datasets for Robot Manipulation*  
  [page](https://robo-mimiclabs.github.io/pages/study.html). ICLR25

- Mar 24 | *Universal Manipulation Interface In-The-Wild Robot Teaching Without In-The-Wild Robots*  
  [page](https://umi-gripper.github.io/). Chi. RSS24.

- Jun 25 | *Lift3D Foundation Policy: Lifting 2D Large-Scale Pretrained Models for Robust 3D Robotic Manipulation*  
  [page](https://lift3d-web.github.io/). CVPR25.

## World Models

- May 18 | *World Models*  
  [page](https://worldmodels.github.io/). NIPS18

- Mar 20 | *Dream to Control: Learning Behaviors by Latent Imagination*  
  [GitHub](https://github.com/google-research/dreamer). ICLR20. Danijar.
  
- Jun 22 | *DayDreamer: World Models for Physical Robot Learning*  
  [GitHub](https://github.com/danijar/daydreamer). Berkeley. Danijar. Robots learn online and directly in the real world, without any simulators.

- Apr 25 | *Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets*  
  [page](https://weirdlabuw.github.io/uwm/), [GitHub](https://github.com/WEIRDLabUW/unified-world-model). RSS25. A policy, a forward dynamics, an inverse dynamics, and a video generator.

- Apr 25 | *Unified Video Action Model*  
  [GitHub](https://github.com/ShuangLI59/unified_video_action). RSS25. Shuran Song's lab.

- May 25 | *LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation*  
  [arxiv](https://arxiv.org/pdf/2505.11528)

- May 25 | *EWMBENCH: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models*  
  [GitHub](https://github.com/AgibotTech/EWMBench)

- Apr 25 | *TesserAct: Learning 4D Embodied World Models*  
  [page](https://tesseractworld.github.io/)

- May 25 | *Learning 3D Persistent Embodied World Models*  
  [arxiv](https://arxiv.org/pdf/2505.05495)

- May 25 | *Vid2World: Crafting Video Diffusion Models to Interactive World Models*  
  [page](https://knightnemo.github.io/vid2world/)

- May 25 | *PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation*  
  [page](https://pinwm.github.io/). RSS25

- May 25 | *Occupancy World Model for Robots*  
  [arxiv](https://arxiv.org/pdf/2505.05512)

- Jun 25 | *WoMAP: World Models For Embodied Open-Vocabulary Object Localization*  
  [page](https://robot-womap.github.io/).

- Jun 25 | *DeepVerse: 4D Autoregressive Video Generation as a World Model*  
  [page](https://sotamak1r.github.io/deepverse/).

- Jun 25 | *FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution*  
  [arxiv](https://arxiv.org/pdf/2506.03173).

- Jun 25 | *3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model*  
  [GitHub](https://github.com/Hoyyyaard/3DFlowAction/).

## Humanoid from Human

- May 25 | *Visual Imitation Enables Contextual Humanoid Control*  
  [page](https://www.videomimic.net/). Berkeley

## Vision

- May 25 | *Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation*  
  [page](https://aalmuzairee.github.io/mad/)
