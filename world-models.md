# World Models Paper List

## Not Categorized

- May 18 | *World Models*  
  [page](https://worldmodels.github.io/). NIPS18

- Mar 20 | *Dream to Control: Learning Behaviors by Latent Imagination*  
  [GitHub](https://github.com/google-research/dreamer). ICLR20. Danijar.
  
- Jun 22 | *DayDreamer: World Models for Physical Robot Learning*  
  [GitHub](https://github.com/danijar/daydreamer). Berkeley. Danijar. Robots learn online and directly in the real world, without any simulators.

- Apr 25 | *Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets*  
  [page](https://weirdlabuw.github.io/uwm/), [GitHub](https://github.com/WEIRDLabUW/unified-world-model). RSS25. A policy, a forward dynamics, an inverse dynamics, and a video generator.

- Apr 25 | *Unified Video Action Model*  
  [GitHub](https://github.com/ShuangLI59/unified_video_action). RSS25. Shuran Song's lab.

- May 25 | *LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation*  
  [arxiv](https://arxiv.org/pdf/2505.11528)

- May 25 | *EWMBENCH: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models*  
  [GitHub](https://github.com/AgibotTech/EWMBench)

- Apr 25 | *TesserAct: Learning 4D Embodied World Models*  
  [page](https://tesseractworld.github.io/)

- May 25 | *Learning 3D Persistent Embodied World Models*  
  [arxiv](https://arxiv.org/pdf/2505.05495)

- May 25 | *Vid2World: Crafting Video Diffusion Models to Interactive World Models*  
  [page](https://knightnemo.github.io/vid2world/)

- May 25 | *PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation*  
  [page](https://pinwm.github.io/). RSS25

- May 25 | *Occupancy World Model for Robots*  
  [arxiv](https://arxiv.org/pdf/2505.05512)

- Jun 25 | *WoMAP: World Models For Embodied Open-Vocabulary Object Localization*  
  [page](https://robot-womap.github.io/).

- Jun 25 | *DeepVerse: 4D Autoregressive Video Generation as a World Model*  
  [page](https://sotamak1r.github.io/deepverse/).

- Jun 25 | *FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution*  
  [arxiv](https://arxiv.org/pdf/2506.03173).

- Jun 25 | *3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model*  
  [GitHub](https://github.com/Hoyyyaard/3DFlowAction/).

- Jun 25 | *AMPLIFY: Actionless Motion Priors for Robot Learning from Videos*  
  [page](https://amplify-robotics.github.io/). Learn a latent keypoint dynamics model to separate motion prediction and action inference.

- Nov 24 | *DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning*  
  [arxiv](https://arxiv.org/pdf/2411.04983). LeCun.

- Jun 25 | *V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning*  
  [GitHub](https://github.com/facebookresearch/vjepa2). LeCun.

- May 25 | *OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation*  
  [arxiv](https://arxiv.org/pdf/2505.20425). LeCun.

- Jun 25 | *DiWA: Diffusion Policy Adaptation with World Models*  
  [OpenReview](https://openreview.net/pdf?id=B066epymUG). RSS25 Workshop.

- Jun 25 | *FLARE: Robot Learning with Implicit World Modeling*  
  [page](https://research.nvidia.com/labs/gear/flare/). Nvidia GEAR.

## Reports or Lists

- Jun 22 | *A Path Towards Autonomous Machine Intelligence*
  [OpenReview](https://openreview.net/pdf?id=BZ5a1r-kVsf). LeCun.

- [Awesome-World-Model](https://github.com/LMD0311/Awesome-World-Model)

- [Awesome-World-Models](https://github.com/leofan90/Awesome-World-Models)
